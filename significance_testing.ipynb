{"cells":[{"cell_type":"markdown","source":"To run this notebook, it is required that experiment results are available in `./results/` with the model results in `./results/baseline`, `./results/dataset-embeddings` and `./results/special-token`.","metadata":{"cell_id":"e4dd2623f98c4ebba14cc18b4913ef50","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"from collections import defaultdict\nfrom functools import partial\nimport numpy as np\nfrom deepsig import aso \n\n!pip install --upgrade pandas jinja2 tabulate --target /usr/local/lib/python3.8/site-packages/\nimport sys\nsys.path = ['/usr/local/lib/python3.8/site-packages', '/shared-libs/python3.8/py-core/lib/python3.8/site-packages']\nimport pandas as pd","metadata":{"cell_id":"a691532e59404c9f9e08f0df6d14a2e2","source_hash":"9a9e36e1","execution_start":1684154563535,"execution_millis":13888,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Collecting pandas\n  Using cached pandas-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\nCollecting jinja2\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting tabulate\n  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\nCollecting python-dateutil>=2.8.2\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting tzdata>=2022.1\n  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\nCollecting numpy>=1.20.3\n  Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\nCollecting pytz>=2020.1\n  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\nCollecting MarkupSafe>=2.0\n  Using cached MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting six>=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, tzdata, tabulate, six, numpy, MarkupSafe, python-dateutil, jinja2, pandas\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsnowflake-connector-python 2.8.0 requires cryptography<37.0.0,>=3.1.0, but you have cryptography 38.0.4 which is incompatible.\nsnowflake-connector-python 2.8.0 requires urllib3<1.27,>=1.21.1, but you have urllib3 2.0.2 which is incompatible.\nbotocore 1.27.95 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed MarkupSafe-2.1.2 jinja2-3.1.2 numpy-1.24.3 pandas-2.0.1 python-dateutil-2.8.2 pytz-2023.3 six-1.16.0 tabulate-0.9.0 tzdata-2023.3\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"models = [\"dataset-embeddings\",\"special-token\",\"baseline\"]\ndomains = [\"ai\", \"literature\", \"news\", \"politics\", \"science\", \"music\"]\nseeds = [\"4012\", \"5096\", \"8878\", \"8857\", \"9908\"]\n\nM = len(domains)\n\ndata = defaultdict(partial(defaultdict, dict))\nfor model in models:\n    for domain in domains:\n        for seed in seeds:\n            data[model][seed][domain] = pd.read_json(f\"results/{model}/rs{seed}/{domain}-test-pred-results.json\")\n\nbaseline = data['baseline']\nspecial_tokens = data['special-token']\ndata_embeddings = data['dataset-embeddings']","metadata":{"cell_id":"ac624402e28046b1bdb1c134e3362dd7","source_hash":"d64f5e8b","execution_start":1684154134038,"execution_millis":1479,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"baseline_scores_per_dataset = [np.array([baseline[seed][domain]['weighted avg']['f1-score'] for seed in seeds]) for domain in domains]\nspecial_scores_per_dataset = [np.array([special_tokens[seed][domain]['weighted avg']['f1-score'] for seed in seeds]) for domain in domains]\ndata_embed_scores_per_dataset = [np.array([data_embeddings[seed][domain]['weighted avg']['f1-score'] for seed in seeds]) for domain in domains]","metadata":{"cell_id":"c809901bcc7e470ab61c2fa06030efbc","source_hash":"cc7490c2","execution_start":1684154135526,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(\"Special Tokens vs. Baseline\")\nspecial_vs_baseline = [aso(a, b, confidence_level=0.95, num_comparisons=M, seed=42) for a, b in zip(special_scores_per_dataset, baseline_scores_per_dataset)]\nprint(\"Dataset embeddings vs. Baseline\")\nembs_vs_baseline = [aso(a, b, confidence_level=0.95, num_comparisons=M, seed=42) for a, b in zip(data_embed_scores_per_dataset, baseline_scores_per_dataset)]","metadata":{"cell_id":"7c1299f078f746228a062a8f322c3df4","source_hash":"a99ee46","execution_start":1684154135532,"execution_millis":105534,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Special Tokens vs. Baseline\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 115.12it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 115.87it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:10<00:00, 91.64it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 115.62it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.97it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.79it/s]\nDataset embeddings vs. Baseline\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 115.00it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 115.32it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.23it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 117.18it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 117.51it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 118.48it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(f\"\"\"Significance testing of scores.\nIf the returned eps_min < 0.5, A is better than B and if eps_min > 0.5, B is better than A. \nThe lower eps_min, the more confident the result\nSpecial Tokens (A) vs. Baseline (B): {special_vs_baseline}\nDataset Embeddings (A) vs. Baseline (B) {embs_vs_baseline}\"\"\")","metadata":{"cell_id":"da01c66402a34b048b2f7b454438ca71","source_hash":"eb585144","execution_start":1684154241063,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Significance testing of scores.\nIf the returned eps_min < 0.5, A is better than B and if eps_min > 0.5, B is better than A. \nThe lower eps_min, the more confident the result\nSpecial Tokens (A) vs. Baseline (B): [1.0, 0.661324495367533, 0.9504284510220415, 0.6590580577951596, 1.0, 0.7869886819598515]\nDataset Embeddings (A) vs. Baseline (B) [0.9960666166719527, 0.995270209415167, 1.0, 0.9956742251446987, 0.9953167096825037, 0.9962299841299801]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"columns = {r\"\\textsc{Seed}\": [r\"\\textsc{Special Tokens vs. Baseline}\", r\"\\textsc{Dataset Embeddings vs. Baseline}\"]}\nfor seed, score1, score2 in zip(seeds, special_vs_baseline, embs_vs_baseline):\n    columns[seed] = [score1, score2]\nprint(pd.DataFrame(columns).to_latex(index=False, float_format=\"%.3f\"))","metadata":{"cell_id":"b958e2635d2e40d2a9f055b66a22e6b4","source_hash":"b19c5c8","execution_start":1684155598717,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"\\begin{tabular}{lrrrrr}\n\\toprule\n\\textsc{Seed} & 4012 & 5096 & 8878 & 8857 & 9908 \\\\\n\\midrule\n\\textsc{Special Tokens vs. Baseline} & 1.000 & 0.661 & 0.950 & 0.659 & 1.000 \\\\\n\\textsc{Dataset Embeddings vs. Baseline} & 0.996 & 0.995 & 1.000 & 0.996 & 0.995 \\\\\n\\bottomrule\n\\end{tabular}\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"\nfor seed in seeds:\n    base = 0\n    spec = 0\n    data = 0\n    for domain in domains:\n        b = baseline[seed][domain]['weighted avg']['f1-score']\n        s = special_tokens[seed][domain]['weighted avg']['f1-score']\n        d = data_embeddings[seed][domain]['weighted avg']['f1-score']\n        base += b\n        spec += s\n        data += d\n        print(domain, seed)\n        print(\"base: \", b)\n        print(\"spec: \", s>b,\"\\t\",s)\n        print(\"data: \", d>b,\"\\t\",d)\n        print(\"--\"*20)\n\n    #print(\"baseline: \", base/len(domains))\n    #print(\"special: \", spec/len(domains))\n    #print(\"data: \", data/len(domains))\n    #print(\"-----------------------------\")","metadata":{"cell_id":"8c283308c9c14ba29ca152e18906b4da","source_hash":"758dddb8","execution_start":1684144105212,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"ai 4012\nbase:  0.45670097683494704\nspec:  False \t 0.455504318935575\ndata:  False \t 0.058728519097733\n----------------------------------------\nliterature 4012\nbase:  0.652635996804101\nspec:  False \t 0.650677808111603\ndata:  False \t 0.058716458223239\n----------------------------------------\nnews 4012\nbase:  0.5108526950197061\nspec:  True \t 0.515817925987182\ndata:  True \t 0.5966607507672991\n----------------------------------------\npolitics 4012\nbase:  0.5603914256081131\nspec:  True \t 0.5957128996282951\ndata:  False \t 0.24625683256972403\n----------------------------------------\nscience 4012\nbase:  0.43147266209719004\nspec:  True \t 0.44974953300445003\ndata:  False \t 0.06746868697699901\n----------------------------------------\nmusic 4012\nbase:  0.7266552581777831\nspec:  True \t 0.7340624520705931\ndata:  False \t 0.141415851323511\n----------------------------------------\nai 5096\nbase:  0.516517806060668\nspec:  False \t 0.48362152177708506\ndata:  False \t 0.058728519097733\n----------------------------------------\nliterature 5096\nbase:  0.6666743506568551\nspec:  True \t 0.6812794147559971\ndata:  False \t 0.058716458223239\n----------------------------------------\nnews 5096\nbase:  0.38798224381437\nspec:  True \t 0.40673896500579304\ndata:  True \t 0.5545109949056181\n----------------------------------------\npolitics 5096\nbase:  0.57619883943173\nspec:  True \t 0.586914278132314\ndata:  False \t 0.24625683256972403\n----------------------------------------\nscience 5096\nbase:  0.49595475216206103\nspec:  False \t 0.43711601990616006\ndata:  False \t 0.042975093357086006\n----------------------------------------\nmusic 5096\nbase:  0.7366274697023011\nspec:  False \t 0.7186471813952731\ndata:  False \t 0.141415851323511\n----------------------------------------\nai 8878\nbase:  0.49555144290227704\nspec:  False \t 0.4927387737223\ndata:  False \t 0.058728519097733\n----------------------------------------\nliterature 8878\nbase:  0.6618989441456441\nspec:  True \t 0.662433780727065\ndata:  False \t 0.069163701914113\n----------------------------------------\nnews 8878\nbase:  0.501184174973183\nspec:  False \t 0.5002432365736931\ndata:  False \t 0.304701561065197\n----------------------------------------\npolitics 8878\nbase:  0.57829438270083\nspec:  True \t 0.600222936757248\ndata:  False \t 0.24625683256972403\n----------------------------------------\nscience 8878\nbase:  0.454034355073246\nspec:  True \t 0.476639797977827\ndata:  False \t 0.014475429790609002\n----------------------------------------\nmusic 8878\nbase:  0.7349283386923461\nspec:  True \t 0.7428366280304871\ndata:  False \t 0.141415851323511\n----------------------------------------\nai 8857\nbase:  0.49451969212040003\nspec:  False \t 0.44552286755755505\ndata:  False \t 0.058728519097733\n----------------------------------------\nliterature 8857\nbase:  0.674629258655693\nspec:  False \t 0.648175184673889\ndata:  False \t 0.058716458223239\n----------------------------------------\nnews 8857\nbase:  0.5320032919308281\nspec:  False \t 0.5191815182730091\ndata:  True \t 0.534878849026382\n----------------------------------------\npolitics 8857\nbase:  0.59234267235437\nspec:  False \t 0.548585442223387\ndata:  False \t 0.24625683256972403\n----------------------------------------\nscience 8857\nbase:  0.453317164022827\nspec:  False \t 0.42956201590978105\ndata:  False \t 0.06746868697699901\n----------------------------------------\nmusic 8857\nbase:  0.741064208855404\nspec:  False \t 0.718738281494081\ndata:  False \t 0.141415851323511\n----------------------------------------\nai 9908\nbase:  0.47730115921151905\nspec:  True \t 0.49402797123371905\ndata:  False \t 0.058728519097733\n----------------------------------------\nliterature 9908\nbase:  0.6483053608965931\nspec:  True \t 0.6800314744139431\ndata:  False \t 0.058716458223239\n----------------------------------------\nnews 9908\nbase:  0.516699092525439\nspec:  True \t 0.5228747505757521\ndata:  False \t 0.48654444925371004\n----------------------------------------\npolitics 9908\nbase:  0.570372604251244\nspec:  True \t 0.590444263130363\ndata:  False \t 0.24625683256972403\n----------------------------------------\nscience 9908\nbase:  0.43920238916666005\nspec:  True \t 0.48098922043401904\ndata:  False \t 0.06746868697699901\n----------------------------------------\nmusic 9908\nbase:  0.67841831727537\nspec:  True \t 0.7253585224219631\ndata:  False \t 0.141415851323511\n----------------------------------------\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from itertools import chain\n\n\nbaseline_scores = []\nlabels = [\n    \"related-to\",\n    \"artifact\",\n    \"cause-effect\",\n    \"compare\",\n    \"general-affiliation\",\n    \"named\",\n    \"opposite\",\n    \"origin\",\n    \"part-of\",\n    \"physical\",\n    \"role\",\n    \"social\",\n    \"temporal\",\n    \"type-of\",\n    \"usage\",\n    \"win-defeat\",\n]\ncolumns_baseline = {domain: [] for domain in domains}\ncolumns_special = {domain: [] for domain in domains}\ncolumns_dataset = {domain: [] for domain in domains}\nmodel_columns = [columns_baseline, columns_special, columns_dataset]\nmodel_results = [baseline, special_tokens, data_embeddings]\n\nfor model, columns in zip(model_results, model_columns):\n    for domain in domains:\n        for label in labels:\n            f1 = (\n                sum(model[seed][domain][label][\"f1-score\"] for seed in seeds)\n                / len(seeds)\n                if model[seed][domain][label][\"support\"] > 0\n                else \"-\"\n            )\n            columns[domain].append(f1)\n\ndomain_to_faicon = {\n    \"ai\": \"\\\\faRobot\",\n    \"music\": \"\\\\faMusic\",\n    \"literature\": \"\\\\faBookOpen\",\n    \"science\": \"\\\\faLeaf\",\n    \"news\": \"\\\\faNewspaper\",\n    \"politics\": \"\\\\faLandmark\",\n}\n\nmodel_names = [\"Baseline\", \"Special tokens\", \"Dataset embeddings\"]\nrows = [\n    list(chain(*((fr\"\\textsc{{{model_name}}}\",) * len(labels) for model_name in model_names))),\n    list(map(lambda x: fr\"\\textsc{{{x}}}\", labels)) * 3,\n]\ncolumns = {domain_to_faicon[domain]: [] for domain in domains}\nfor model_results in model_columns:\n    for domain, scores in model_results.items():\n        columns[domain_to_faicon[domain]].extend(scores)\nprint(\n    pd.DataFrame(\n        columns,\n        index=rows,\n    ).to_latex(float_format=\"%.2f\")\n)\n","metadata":{"cell_id":"44b49a1b94a242638d337104965d8b2a","source_hash":"d3bff958","execution_start":1684145400975,"execution_millis":83,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"\\begin{tabular}{llrrllrr}\n\\toprule\n &  & \\faRobot & \\faBookOpen & \\faNewspaper & \\faLandmark & \\faLeaf & \\faMusic \\\\\n\\midrule\n\\multirow[t]{16}{*}{\\textsc{Baseline}} & \\textsc{related-to} & 0.41 & 0.10 & 0.00 & 0.05 & 0.40 & 0.07 \\\\\n & \\textsc{artifact} & 0.65 & 0.89 & - & 0.36 & 0.59 & 0.86 \\\\\n & \\textsc{cause-effect} & 0.00 & 0.00 & - & - & 0.00 & 0.00 \\\\\n & \\textsc{compare} & 0.03 & 0.00 & - & 0.00 & 0.12 & 0.00 \\\\\n & \\textsc{general-affiliation} & 0.14 & 0.83 & 0.32 & 0.36 & 0.44 & 0.85 \\\\\n & \\textsc{named} & 0.79 & 0.61 & 0.41 & 0.76 & 0.65 & 0.45 \\\\\n & \\textsc{opposite} & 0.09 & 0.00 & 0.09 & 0.22 & 0.00 & 0.00 \\\\\n & \\textsc{origin} & 0.54 & 0.28 & - & 0.20 & 0.43 & 0.30 \\\\\n & \\textsc{part-of} & 0.51 & 0.15 & 0.03 & 0.19 & 0.28 & 0.29 \\\\\n & \\textsc{physical} & 0.85 & 0.82 & 0.71 & 0.78 & 0.79 & 0.94 \\\\\n & \\textsc{role} & 0.69 & 0.64 & 0.64 & 0.56 & 0.48 & 0.64 \\\\\n & \\textsc{social} & 0.00 & 0.48 & - & 0.24 & 0.28 & 0.07 \\\\\n & \\textsc{temporal} & 0.70 & 0.74 & 0.24 & 0.87 & 0.63 & 0.50 \\\\\n & \\textsc{type-of} & 0.24 & 0.76 & - & 0.04 & 0.09 & 0.74 \\\\\n & \\textsc{usage} & 0.11 & 0.00 & - & - & 0.00 & 0.07 \\\\\n & \\textsc{win-defeat} & 0.75 & 0.75 & 0.00 & 0.08 & 0.84 & 0.81 \\\\\n\\cline{1-8}\n\\multirow[t]{16}{*}{\\textsc{Special tokens}} & \\textsc{related-to} & 0.37 & 0.17 & 0.18 & 0.07 & 0.43 & 0.13 \\\\\n & \\textsc{artifact} & 0.60 & 0.87 & - & 0.43 & 0.59 & 0.86 \\\\\n & \\textsc{cause-effect} & 0.00 & 0.00 & - & - & 0.00 & 0.00 \\\\\n & \\textsc{compare} & 0.01 & 0.00 & - & 0.00 & 0.16 & 0.00 \\\\\n & \\textsc{general-affiliation} & 0.18 & 0.84 & 0.25 & 0.35 & 0.48 & 0.86 \\\\\n & \\textsc{named} & 0.76 & 0.62 & 0.39 & 0.74 & 0.63 & 0.50 \\\\\n & \\textsc{opposite} & 0.06 & 0.09 & 0.10 & 0.27 & 0.00 & 0.05 \\\\\n & \\textsc{origin} & 0.53 & 0.34 & - & 0.20 & 0.42 & 0.34 \\\\\n & \\textsc{part-of} & 0.50 & 0.18 & 0.11 & 0.25 & 0.27 & 0.31 \\\\\n & \\textsc{physical} & 0.87 & 0.82 & 0.69 & 0.78 & 0.80 & 0.95 \\\\\n & \\textsc{role} & 0.66 & 0.64 & 0.65 & 0.57 & 0.41 & 0.63 \\\\\n & \\textsc{social} & 0.20 & 0.51 & - & 0.42 & 0.43 & 0.23 \\\\\n & \\textsc{temporal} & 0.72 & 0.76 & 0.35 & 0.86 & 0.68 & 0.50 \\\\\n & \\textsc{type-of} & 0.22 & 0.62 & - & 0.00 & 0.10 & 0.72 \\\\\n & \\textsc{usage} & 0.11 & 0.00 & - & - & 0.00 & 0.01 \\\\\n & \\textsc{win-defeat} & 0.77 & 0.74 & 0.01 & 0.13 & 0.84 & 0.77 \\\\\n\\cline{1-8}\n\\multirow[t]{16}{*}{\\textsc{Dataset embeddings}} & \\textsc{related-to} & 0.00 & 0.00 & 0.03 & 0.00 & 0.03 & 0.00 \\\\\n & \\textsc{artifact} & 0.00 & 0.25 & - & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{cause-effect} & 0.00 & 0.00 & - & - & 0.00 & 0.00 \\\\\n & \\textsc{compare} & 0.00 & 0.00 & - & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{general-affiliation} & 0.00 & 0.07 & 0.00 & 0.00 & 0.00 & 0.47 \\\\\n & \\textsc{named} & 0.00 & 0.00 & 0.64 & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{opposite} & 0.00 & 0.00 & 0.11 & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{origin} & 0.00 & 0.00 & - & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{part-of} & 0.32 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{physical} & 0.00 & 0.00 & 0.67 & 0.00 & 0.06 & 0.00 \\\\\n & \\textsc{role} & 0.00 & 0.00 & 0.71 & 0.63 & 0.20 & 0.00 \\\\\n & \\textsc{social} & 0.00 & 0.00 & - & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{temporal} & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{type-of} & 0.00 & 0.00 & - & 0.00 & 0.00 & 0.00 \\\\\n & \\textsc{usage} & 0.00 & 0.00 & - & - & 0.00 & 0.00 \\\\\n & \\textsc{win-defeat} & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n\\cline{1-8}\n\\bottomrule\n\\end{tabular}\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from IPython.display import display, HTML\n\ndisplay(\n    HTML(\n        pd.DataFrame(\n            {domain_to_faicon[domain]: v for domain, v in columns_baseline.items()},\n            index=list(map(lambda x: fr\"\\textsc{{{x}}}\", labels)),\n        ).to_html(float_format=lambda x: f\"{x:.2f}\")\n    )\n)","metadata":{"cell_id":"96e6bfd96f1148e6bb8f1be9c12688a2","source_hash":"a71ab745","execution_start":1684144105388,"execution_millis":15,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>\\faRobot</th>\n      <th>\\faBookOpen</th>\n      <th>\\faNewspaper</th>\n      <th>\\faLandmark</th>\n      <th>\\faLeaf</th>\n      <th>\\faMusic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>\\textsc{related-to}</th>\n      <td>0.41</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>\\textsc{artifact}</th>\n      <td>0.65</td>\n      <td>0.89</td>\n      <td>-</td>\n      <td>0.36</td>\n      <td>0.59</td>\n      <td>0.86</td>\n    </tr>\n    <tr>\n      <th>\\textsc{cause-effect}</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>-</td>\n      <td>-</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>\\textsc{compare}</th>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>-</td>\n      <td>0.00</td>\n      <td>0.12</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>\\textsc{general-affiliation}</th>\n      <td>0.14</td>\n      <td>0.83</td>\n      <td>0.32</td>\n      <td>0.36</td>\n      <td>0.44</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>\\textsc{named}</th>\n      <td>0.79</td>\n      <td>0.61</td>\n      <td>0.41</td>\n      <td>0.76</td>\n      <td>0.65</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>\\textsc{opposite}</th>\n      <td>0.09</td>\n      <td>0.00</td>\n      <td>0.09</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>\\textsc{origin}</th>\n      <td>0.54</td>\n      <td>0.28</td>\n      <td>-</td>\n      <td>0.20</td>\n      <td>0.43</td>\n      <td>0.30</td>\n    </tr>\n    <tr>\n      <th>\\textsc{part-of}</th>\n      <td>0.51</td>\n      <td>0.15</td>\n      <td>0.03</td>\n      <td>0.19</td>\n      <td>0.28</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>\\textsc{physical}</th>\n      <td>0.85</td>\n      <td>0.82</td>\n      <td>0.71</td>\n      <td>0.78</td>\n      <td>0.79</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>\\textsc{role}</th>\n      <td>0.69</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.56</td>\n      <td>0.48</td>\n      <td>0.64</td>\n    </tr>\n    <tr>\n      <th>\\textsc{social}</th>\n      <td>0.00</td>\n      <td>0.48</td>\n      <td>-</td>\n      <td>0.24</td>\n      <td>0.28</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>\\textsc{temporal}</th>\n      <td>0.70</td>\n      <td>0.74</td>\n      <td>0.24</td>\n      <td>0.87</td>\n      <td>0.63</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>\\textsc{type-of}</th>\n      <td>0.24</td>\n      <td>0.76</td>\n      <td>-</td>\n      <td>0.04</td>\n      <td>0.09</td>\n      <td>0.74</td>\n    </tr>\n    <tr>\n      <th>\\textsc{usage}</th>\n      <td>0.11</td>\n      <td>0.00</td>\n      <td>-</td>\n      <td>-</td>\n      <td>0.00</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>\\textsc{win-defeat}</th>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.08</td>\n      <td>0.84</td>\n      <td>0.81</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{},"output_type":"display_data"}],"execution_count":10},{"cell_type":"markdown","source":"### ASO comparisons between dataset-embeddings with different entity markers","metadata":{"cell_id":"731203a122874e2291766bb5fbc2e952","formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"marker_types = [\"all\", \"generic\", \"none\"]\ndataframes = {marker: {seed: {} for seed in seeds} for marker in marker_types}\nfor seed in seeds:\n    for marker in marker_types:\n        for domain in domains:\n            dataframes[marker][seed][domain] = pd.read_json(f\"results_all/dataset-embeddings-{marker}/rs{seed}/{domain}-test-pred-results.json\")\n\ndataset_embeddings_all_per_dataset = [np.array([dataframes[\"all\"][seed][domain][\"weighted avg\"][\"f1-score\"] for seed in seeds]) for domain in domains]\ndataset_embeddings_generic_per_dataset = [np.array([dataframes[\"generic\"][seed][domain][\"weighted avg\"][\"f1-score\"] for seed in seeds]) for domain in domains]\ndataset_embeddings_none_per_dataset = [np.array([dataframes[\"none\"][seed][domain][\"weighted avg\"][\"f1-score\"] for seed in seeds]) for domain in domains]\n\nall_vs_none = [aso(a, b, confidence_level=0.95, num_comparisons=M, seed=42) for a, b in zip(dataset_embeddings_all_per_dataset, dataset_embeddings_none_per_dataset)]\ngeneric_vs_none = [aso(a, b, confidence_level=0.95, num_comparisons=M, seed=42) for a, b in zip(dataset_embeddings_generic_per_dataset, dataset_embeddings_none_per_dataset)]\ngeneric_vs_all = [aso(a, b, confidence_level=0.95, num_comparisons=M, seed=42) for a, b in zip(dataset_embeddings_generic_per_dataset, dataset_embeddings_all_per_dataset)]\nprint(f\"\"\"Significance testing of scores.\nIf the returned eps_min < 0.5, A is better than B and if eps_min > 0.5, B is better than A. \nThe lower eps_min, the more confident the result\nAll entity types (A) vs. No entity types (B): {all_vs_none}\nGeneric entity types (A) vs. No entity types (B) {generic_vs_none}\nGeneric entity types (A) vs. All entity types (B) {generic_vs_all}\"\"\")","metadata":{"cell_id":"e27bb8fe7e874be8a8d8bd8017f366f2","source_hash":"4b41ced4","execution_start":1684154271518,"execution_millis":171002,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"Bootstrap iterations:   0%|          | 0/1000 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/deepsig/aso.py:390: UserWarning: Division by zero encountered in violation ratio.\n  warn(\"Division by zero encountered in violation ratio.\")\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.57it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.46it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 115.54it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.05it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.17it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.09it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 113.77it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 113.70it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:09<00:00, 100.90it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:09<00:00, 101.04it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:13<00:00, 73.24it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:14<00:00, 69.69it/s] \nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 112.98it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 114.39it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.30it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 112.25it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 116.46it/s]\nBootstrap iterations: 100%|█████████▉| 999/1000 [00:08<00:00, 113.16it/s]Significance testing of scores.\nIf the returned eps_min < 0.5, A is better than B and if eps_min > 0.5, B is better than A. \nThe lower eps_min, the more confident the result\nAll entity types (A) vs. No entity types (B): [1.0, 0.404223106554111, 1.0, 0.5, 1.0, 0.5]\nGeneric entity types (A) vs. No entity types (B) [0.5, 0.404223106554111, 0.6677991175012025, 0.5, 1.0, 0.5]\nGeneric entity types (A) vs. All entity types (B) [0.4086645426453539, 1.0, 0.2824481858198506, 0.5, 1.0, 0.5]\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6c3be415-6b72-4ca4-8444-c76a32e3ce00' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"1c47be9974284b7cb45839d83614f5f7","deepnote_execution_queue":[]}}